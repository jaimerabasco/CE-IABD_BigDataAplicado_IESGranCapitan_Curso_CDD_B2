# UD 1 - Gesti√≥n de Soluciones

_[ver presentaci√≥n BDA1.1](https://moodle.iesgrancapitan.org/pluginfile.php/57450/mod_folder/content/0/BDA_UD1_01.pdf?forcedownload=1)_
## 1.1. Introducci√≥n de los datos al conocimiento

El **dato** es una representaci√≥n sint√°ctica, generalmente num√©rica, que puede manejar un dispositivo electr√≥nico - normalmente un ordenador - sin significado por s√≠ solo. Sin embargo, el dato es a su vez el ingrediente fundamental y el elemento de entrada necesario en cualquier sistema y/o proceso que pretenda extraer informaci√≥n o conocimiento sobre un dominio determinado. En este sentido, 7 es un dato, como tambi√©n lo es œÄ o como son los t√©rminos aprobado o suspenso.

Por su parte, la **informaci√≥n** es el dato interpretado, es decir, el dato con significado. Para obtener informaci√≥n, ha sido necesario un proceso en el que, a partir de un dato como elemento de entrada, se realice una **interpretaci√≥n** de ese dato que permita obtener su significado, es decir, informaci√≥n a partir de √©l. La informaci√≥n es tambi√©n el elemento de entrada y de salida en cualquier proceso de toma de decisiones. Partiendo de los datos del ejemplo anterior, informaci√≥n obtenida a partir de los mismos puede ser: El 7 es un n√∫mero primo, œÄ es una constante cuyo valor es 3, 141592653..., Mar√≠a ha aprobado el examen de conducir, Pablo est√° suspenso en matem√°ticas.

A partir de informaci√≥n, es posible construir conocimiento. El **conocimiento** es informaci√≥n aprendida, que se traduce a su vez en reglas, asociaciones, algoritmos, etc. que permiten resolver el proceso de toma de decisiones. As√≠ pues, la informaci√≥n obtenida a partir de los datos permite generar conocimiento, es decir, aprender. El conocimiento no es est√°tico, como tampoco lo es siempre el aprendizaje. Aprender, construir conocimiento, implica necesariamente contrastar y validar el conocimiento construido con nueva informaci√≥n que permita, a su vez, guiar el aprendizaje y construir conocimiento nuevo. Siguiendo con los ejemplos anteriores, el conocimiento que permite obtener que el 7 es un n√∫mero primo puede ser el _algoritmo de Erat√≥stenes_. Por otra parte, el conocimiento que permite obtener el valor del n√∫mero œÄ puede extraerse de los resultados de los trabajos de _Jones, Euler o Arqu√≠medes_, mientras que el aprobado de Mar√≠a en el examen de conducir y el suspenso de Pablo en matem√°ticas, se pueden obtener de la regla que en una escala de diez asigna el aprobado a notas mayores o iguales que 5 y el suspenso a notas menores.

![figura1.1][figura1.1]


_Figura 1: Relaci√≥n entre datos, informaci√≥n y conocimiento en el proceso de toma de decisiones_

Por tanto, datos, informaci√≥n y conocimiento est√°n estrechamente relacionados entre s√≠ y dirigen cualquier proceso de toma de decisiones  La [figura1.1][figura1.1] muestra la relaci√≥n entre datos, informaci√≥n y conocimiento, en un proceso gen√©rico de **toma de decisiones**. M√°s concretamente, en el ejemplo del suspenso de Pablo en matem√°ticas, el proceso de toma de decisi√≥n acerca de la calificaci√≥n de Pablo se estructurar√≠a de la siguiente forma:

1. El profesor corrige el examen de Pablo, que ha sacado un 3. Esta calificaci√≥n, por s√≠ sola, es simplemente un dato.

2. A continuaci√≥n, el profesor calcula la calificaci√≥n final de Pablo, en base a la nota del examen, sus trabajos y pr√°cticas de laboratorio. _La nota final de Pablo es un 4_. Esto √∫ltimo es informaci√≥n.

3. ¬øHa aprobado Pablo? La informaci√≥n de entrada al proceso de decisi√≥n es su calificaci√≥n final de 4 puntos, obtenida en el paso anterior. El conocimiento del profesor sobre el sistema de calificaci√≥n le indica que una nota menor a 5 puntos se corresponde con un suspenso y, en caso contrario, con un aprobado.

4. La informaci√≥n de salida tras este proceso de decisi√≥n es que _Pablo est√° suspenso en matem√°ticas_.

!!! question 

    ‚ùìPregunta. Siguiendo el ejemplo anterior ¬øC√≥mo se produce el proceso de toma de decisiones para determinar si un n√∫mero es primo?

Aunque se trate de un ejemplo trivial, la importancia del proceso de toma de decisiones no lo es. En **marketing**, por ejemplo, se analizan bases de datos de clientes para identificar distintos grupos e intentar predecir el comportamiento de estos. En el mundo de las **finanzas**, las inversiones realizadas por grandes empresas responden a un proceso complejo de toma de decisiones donde los datos son el eje fundamental de este proceso. En **medicina**, existe una gran cantidad de sistemas de ayuda a la decisi√≥n que permiten a los doctores contrastar y validar sus diagn√≥sticos de forma precoz. En definitiva, no hay √°rea de conocimiento ni √°mbito de aplicaci√≥n que escape al proceso de toma de decisiones.

## 1.2 La carrera entre los datos y la tecnolog√≠a

Que los datos son el elemento fundamental en cualquier proceso y/o sistema de **toma de decisiones** no es algo nuevo. Sin embargo, los datos no siempre han estado al alcance de los expertos y no siempre ha sido posible ni sencillo procesarlos seg√∫n las necesidades concretas de cada caso de aplicaci√≥n.

La informaci√≥n, por tanto, siempre ha sido poder y el gran reto ha sido y sigue siendo extraer informaci√≥n a partir de datos para generar conocimiento. Para ello, es necesario contar con dos factores que deben estar alineados: **datos y tecnolog√≠a**.

Obtener **datos** no ha sido siempre una tarea f√°cil. Esto es debido principalmente a que la gran cantidad de sensores disponibles en la actualidad, que permiten registrar magnitudes de cualquier proceso, no exist√≠a como a d√≠a de hoy. Adem√°s, los sensores existentes en esta √©poca (finales del siglo XX y comienzos del siglo XXI) no estaban ampliamente extendidos, ya que sus prestaciones estaban lejos de las que ofrecen hoy y sus precios no estaban al alcance de cualquier usuario. Por tanto, los procesos que se monitorizaban y de los cuales se recog√≠an datos eran, sobretodo, procesos industriales realizados en grandes empresas. Por todos estos motivos, tradicionalmente se recurr√≠a a **modelos de simulaci√≥n** que, a trav√©s de la implementaci√≥n de un modelo matem√°tico, permit√≠an generar datos realistas de un proceso.

Los datos generados mediante simulaci√≥n son conocidos como **datos sint√©ticos** mientras que los datos provenientes de las lecturas de un sensor se conocen como **datos reales**.

Pero con los datos no es suficiente. Es necesario tambi√©n contar con la tecnolog√≠a necesaria para su procesamiento. Generar, almacenar y procesar todos estos datos no es una tarea trivial, y plantea una serie de ptoblemas tecn√≥logicos a resolver.

 - Primer problema tecnol√≥gico a resolver, el **almacenamiento**. Algunas soluciones propuestas pasan por los **sistemas de informaci√≥n distribuida**, entendidos como un conjunto de ordenadores separados f√≠sicamente y conectados en red destinados al almacenamiento de datos o por los **sistemas de informaci√≥n en la nube**, que permiten adquirir espacio de almacenamiento en servidores privados, dejando la gesti√≥n de estos servidores en manos del proveedor.
 - El segundo problema tecnol√≥gico es el **procesamiento** de los datos almacenados. Este aspecto cobra especial relevancia en funci√≥n del caso de aplicaci√≥n, pudiendo distinguirse entre procesamiento on-line (en l√≠nea) y procesamiento off-line (fuera de l√≠nea).
   
   * üíª En el caso del **procesamiento on-line**, los datos son procesados a medida que son generados, ya que se requiere una respuesta en tiempo real. Por ejemplo, en un sistema de control del tr√°fico que permite regular los sem√°foros en funci√≥n del tr√°fico actual, el sistema debe regular el sem√°foro a medida que se van generando e interpretando los datos del tr√°fico en un instante de tiempo dado.
   * ‚ùé Por otra parte, en el caso del **procesamiento off-line**, no es necesario que los datos se procesen a medida que se generan. Por ejemplo, en un sistema de detecci√≥n del fraude bancario, comprobar si un cliente ha realizado alg√∫n movimiento fraudulento es una tarea que puede llevarse a cabo off-line, por ejemplo, haciendo un an√°lisis de los movimientos del cliente en un momento dado, sin tener por qu√© diagnosticar cada movimiento que este va realizando.

En este sentido, la **computaci√≥n distribuida**, en donde m√∫ltiples m√°quinas realizan el procesamiento optimizando el rendimiento o la **computaci√≥n en la nube**, que permite adquirir recursos de procesamiento al igual que se puede adquirir espacio de almacenamiento, son dos soluciones al problema del procesamiento.

Otras alternativas son la **programaci√≥n paralela** y la **programaci√≥n multi-procesador**, que permiten, respectivamente, aprovechar el paralelismo de m√∫ltiples hilos de ejecuci√≥n dentro de un procesador y realizar el procesamiento dividi√©ndolo en m√∫ltiples hilos en diferentes procesadores

!!! question 

    ‚ùì Pregunta. Piensa en procesos cotidianos que requieran un procesamiento on-line y en otros que requieran un procesamiento off-line.

‚è≥ En la actualidad, la proliferaci√≥n de una gran cantidad de sensores con altas prestaciones y precios asequibles que permiten monitorizar y generar datos sobre cualquier proceso ha supuesto un **incremento exponencial en la cantidad de datos generados**. Es posible monitorizar casi cualquier proceso, incluyendo los dom√©sticos como el consumo el√©ctrico de un hogar, la presencia dentro del mismo o procesos cotidianos como la actividad f√≠sica, entre otros muchos. Hoy, los datos llevan la delantera en la carrera entre datos y tecnolog√≠a. Si bien es cierto que la tecnolog√≠a ha experimentado grandes avances en los √∫ltimos a√±os, la cantidad de datos generada no deja de crecer. Esto supone un **reto permanente para la tecnolog√≠a**, que sigue evolucionando a nivel hardware con la aparici√≥n de arquitecturas con mayores posibilidades procesamiento y almacenamiento y a nivel software, con la aparici√≥n de modelos de programaci√≥n que optimizan el procesamiento de los datos.

_[ver presentaci√≥n BDA1.2](https://moodle.iesgrancapitan.org/pluginfile.php/57450/mod_folder/content/0/BDA_UD1_02.pdf?forcedownload=1)_
## 1.3 Los datos: los de ayer y los de hoy

Al igual que la tecnolog√≠a ha ido evolucionando para dar respuesta a la ingente cantidad de datos que ha comenzado a generarse, estos √∫ltimos tambi√©n han experimentado una gran evoluci√≥n. Esta evoluci√≥n, o revoluci√≥n, no est√° √∫nicamente relacionada con la **cantidad** de datos (como se expuso en el anterior apartado) sino tambi√©n con el **tipo** y el **formato** de los mismos.

üíæ Tradicionalmente, el tipo y formato de datos con el que se ha trabajado para extraer informaci√≥n y conocimiento a partir de ellos era ciertamente **limitado**. En muchas ocasiones se trataba de ficheros de datos estructurados de forma tabular, donde cada fila del conjunto de datos representaba una instancia del mismo y cada columna una variable o atributo de la instancia. El formato de archivo que se manejaba sol√≠an ser **formatos de hojas de c√°lculo** (.xlsx, .ods, .numbers etc) o **ficheros separados por comas** (.csv). Muy pocos eran los procesos en los que se trabajaba con otros tipos de datos como texto, im√°genes, audio e incluso v√≠deos, ya que los formatos de estos tipos de datos eran limitados hace unos a√±os, su procesamiento m√°s complejo y la tecnolog√≠a para ello a√∫n en desarrollo.

Aunque a d√≠a de hoy tambi√©n se sigue trabajando con archivos de datos en forma de hojas de c√°lculo y/o archivos tradicionales para generar conocimiento a partir de ellos, las posibilidades actuales son pr√°cticamente **ilimitadas**.

  - ‚úèÔ∏è En cuanto al _texto_, las t√©cnicas de inteligencia artificial y procesamiento del lenguaje natural hacen posible la extracci√≥n de conocimiento a partir de **grandes vol√∫menes de textos**, que pueden provenir de p√°ginas web, archivos .pdf, redes sociales, etc.
  
  - üìπ El desarrollo de hardware con mejores prestaciones y los nuevos modelos de programaci√≥n permiten procesar en la actualidad **grandes cantidades de im√°genes, audios y v√≠deos** con una gran variedad de t√©cnicas de inteligencia artificial en tiempos razonables.

  - ‚ö´ Finalmente, han aparecido nuevos tipos y formatos de datos, como por ejemplo, aquellos datos generados a partir de **grafos**, los cuales se tratar√°n en pr√≥ximas secciones y cap√≠tulos con m√°s detenimiento. Estos datos se corresponden, por ejemplo, con datos geogr√°ficos obtenidos a partir de mapas como los generados en aplicaciones como Google Maps u Open Street Maps o datos de seguimiento y actividad en redes sociales de gran valor en campa√±as publicitarias entre otros muchos.

!!! question 

    ‚ùìPregunta. Haz una b√∫squeda y elabora un listado con distintos tipos de datos y los formatos de almacenamiento m√°s utilizados con los que se trabaja en ciencia de datos y big data.

Los diferentes tipos y formatos de datos, los de ayer y los de hoy, son la materia b√°sica fundamental en cualquier proceso de extracci√≥n de informaci√≥n y de conocimiento. Despu√©s, las metodolog√≠as empleadas para ello y arquitecturas hardware sobre las que se realice el procesamiento de los mismos, permitir√°n definir **procesos y metodolog√≠as de big data**, aplicadas a un √°mbito concreto.

_[ver presentaci√≥n BDA1.3](https://moodle.iesgrancapitan.org/pluginfile.php/57450/mod_folder/content/0/BDA_UD1_03.pdf?forcedownload=1)_
## 1.4 Soluciones Big Data

En esta nueva era tecnol√≥gica en la que nos hayamos inmersos, a diario se generan enormes cantidades de datos, del orden de **petabytes** (m√°s de un mill√≥n de gigabytes) **en muy cortos peri√≥dos de tiempo**. Hoy en d√≠a, cualquier dispositivo como puede ser un reloj, un coche, un smartphone, etc est√° conectado a Internet generando, enviando y recibiendo una gran cantidad de datos. Tanto es as√≠, que se estima que el 90 % de los datos disponibles en el mundo ha sido generado en los √∫ltimos a√±os. Sin lugar a dudas, esta y las pr√≥ximas generaciones ser√°n las generaciones del big data.

Esta realidad descrita anteriormente demanda la capacidad de enviar y recibir datos e informaci√≥n a gran velocidad, as√≠ como la capacidad de almacenar tal cantidad de datos y procesarlos en tiempo real. As√≠ pues, la gran cantidad de datos disponibles junto con las herramientas, tanto hardware como software, que existen a disposici√≥n para analizarlos se conoce como ***big data***.

‚úåÔ∏è No existe una definici√≥n precisa del t√©rmino **big data**, ni tampoco un t√©rmino en castellano que permita denominar este concepto. A veces se usan en castellano los t√©rmino _datos masivos_ o _grandes vol√∫menes de datos_ para hacer referencia al big data. Por este motivo, a menudo el concepto de big data es definido en funci√≥n de las caracter√≠sticas que poseen los datos y los procesos que forman parte de este nuevo paradigma de computaci√≥n. Esto es lo que se conoce como ‚úåÔ∏è **las Vs del big data** ‚úåÔ∏è.

Algunos autores coinciden en que big data son datos cuyo **volumen** es demasiado grande como para procesarlos con las tecnolog√≠as y t√©cnicas tradicionales, requiriendo nuevas arquitecturas hardware, modelos de programaci√≥n y algoritmos para su procesamiento. Adem√°s, se trata de datos que se presentan en una gran **variedad** de estructuras y formatos: datos sint√©ticos, provenientes de sensores, num√©ricos, textuales, im√°genes, audio, v√≠deo... Finalmente, se trata de datos que requieren ser procesados a gran **velocidad** para poder extraer valor y conocimiento de ellos. Esta concepci√≥n se conoce como las tres Vs del big data (ver [figura1.2][figura1.2]).

![figura1.2][figura1.2]


_Figura 1.2: Definici√≥n de big data en base a ‚ÄúLas tres Vs del big data_

Otros autores ampl√≠an las caracter√≠sticas que han de tener los datos que forman parte del big data, incluyendo ‚Äúotras Vs‚Äù como lo son:
   - ‚úåÔ∏è **Volatilidad**, referida al tiempo durante el cual los datos recogidos son v√°lidos y a durante cu√°nto tiempo deber√°n ser almacenados.
   - ‚úåÔ∏è **Valor**, referido a la utilidad de los datos obtenidos para extraer conocimiento y tomar decisiones a partir de ellos.
   - ‚úåÔ∏è **Validez**, referida a lo precisos que son los datos para el uso que se pretende darles. El uso de datos validados permitir√° ahorrar tiempo en etapas como la limpieza y el preprocesamiento de los datos.
   - ‚úåÔ∏è ***Veracidad***, relacionada con la confiabilidad del origen del cual provienen los datos con los que se trabajar√° as√≠ como la incertidumbre o el ruido que pudiera existir en ellos.
   - ‚úåÔ∏è **Variabilidad**, frente a la variedad de estructuras y formatos, hace referencia a la complejidad del conjunto de datos, es decir, al n√∫mero de variables que contiene. Estas caracter√≠sticas, unidas a las tres Vs descritas anteriormente, se conocen como las ocho Vs del big data (ver [figura1.3][figura1.3]).

![figura1.3][figura1.3]


_Figura 1.3: Definici√≥n de big data en base a ‚ÄúLas ocho Vs del big data‚Äù_

Dado que no existe una definici√≥n uniforme para el t√©rmino big data, muchos autores definen el t√©rmino en funci√≥n de aquellas caracter√≠sticas que consideran m√°s relevantes, por lo que es com√∫n encontrar ‚Äúlas cinco Vs del big data‚Äù, ‚Äúlas siete Vs del big data‚Äù o ‚Äúlas diez Vs del big data‚Äù seg√∫n cada autor, apareciendo distintos t√©rminos para describir el big data, como tambi√©n pueden ser **visualizaci√≥n** o **vulnerabilidad**, entre otros. 

Son muchas las **soluciones a nivel hardware y software**, que se han propuesto a los problemas derivados del almacenamiento y el procesamiento de big data. A continuaci√≥n, se describen los fundamentos de tres de ellas, las cuales ser√°n desarrolladas a nivel te√≥rico, tecnol√≥gico y pr√°ctico en los siguientes cap√≠tulos.

_[ver presentaci√≥n BDA1.4](https://moodle.iesgrancapitan.org/pluginfile.php/57450/mod_folder/content/0/BDA_UD1_04.pdf?forcedownload=1)_
### 1.4.1 Almacenes de datos

üíæ Tradicionalmente hablando, cuando nos referimos a almacenes de datos, podemos hablar de las **bases de datos relacionales** son colecciones de datos integrados, almacenados en un soporte secundario no vol√°til y con redundancia controlada. La definici√≥n de los datos y la estructura de la base de datos debe estar basada en un modelo de datos que permita captar las interrelaciones y restricciones existentes en el dominio que se pretende modelizar. A su vez, un **Sistema Gestor de Bases de Datos (SGBD)** se compone de una colecci√≥n de datos estructurados e interrelacionados (una base de datos) as√≠ como de un conjunto de programas para acceder a dichos datos.

üíæ Las bases de datos tradicionales, siguiendo la definici√≥n anterior, est√°n basadas generalmente en sistemas relacionales u objeto-relacionales. Para el acceso, procesamiento y recuperaci√≥n de los datos, se sigue el modelo **Online Transaction Processing (OLTP)**. Una transacci√≥n es una interacci√≥n completa con un sistema de base de datos, que representa una unidad de trabajo. As√≠ pues, una transacci√≥n representa cualquier cambio que se produzca en una base de datos.

üíæ El modelo OLTP, traducido al castellano como **procesamiento de transacciones en l√≠nea**, permite gestionar los cambios de la base de datos mediante la inserci√≥n, actualizaci√≥n y eliminaci√≥n de informaci√≥n de la misma a trav√©s de transacciones b√°sicas que son procesadas en tiempos muy peque√±os.

üíæ Con respecto a la recuperaci√≥n de informaci√≥n de la base de datos, se utilizan operadores cl√°sicos (concatenaci√≥n, proyecci√≥n, selecci√≥n, agrupamiento...) para realizar consultas b√°sicas y sencillas (realizadas, mayoritariamente, en lenguaje SQL y extensiones del mismo).

üíæ Finalmente, las opciones de visualizaci√≥n de los datos recuperados son limitadas, mostr√°ndose fundamentalmente los resultados de forma tabular y requiriendo un procesamiento adicional y m√°s complejo en caso de querer presentar datos complejos.

üîÅ La revoluci√≥n en la generaci√≥n, almacenamiento y procesamiento de los datos, as√≠ como la irrupci√≥n del **big data**, han puesto a prueba el modelo de funcionamiento, rendimiento y escalabilidad de las bases de datos relacionales tradicionales. En la actualidad, se requiere de soluciones integradas que a√∫nen datos y tecnolog√≠a para almacenar y procesar grandes cantidades de datos con diferentes estructuras y formatos con el objetivo de facilitar la consulta, el an√°lisis y la toma de decisiones sobre los mismos. En este sentido, la **inteligencia de negocio**, m√°s conocida por el t√©rmino ingl√©s **business intelligence**, investiga en el dise√±o y desarrollo de este tipo de soluciones. La inteligencia de negocio puede definirse como la capacidad de una empresa de estudiar sus acciones y comportamientos pasados para entender d√≥nde ha estado la empresa, determinar la situaci√≥n actual y predecir o cambiar lo que suceder√° en el futuro, utilizando las soluciones tecnol√≥gicas m√°s apropiadas para optimizar el proceso de toma de decisiones.

Estas nuevas soluciones requerir√°n un modelo de procesamiento diferente a **OLTP**. Esto es as√≠, ya que el objetivo perseguido por la inteligencia de negocio est√° menos orientado al √°mbito transaccional y m√°s enfocado al √°mbito anal√≠tico. Las nuevas soluciones utilizan el modelo **Online analytical processing (OLAP)**.

La principal diferencia entre OLTP y OLAP estriba en que mientras que el primero es un sistema de procesamiento de transacciones en l√≠nea, el segundo es un sistema de **recuperaci√≥n y an√°lisis** de datos en l√≠nea. Por tanto, OLAP complementa a SQL aportando la capacidad de analizar datos desde distintas variables y dimensiones, mejorando el proceso de toma de decisiones. Para ello, OLAP permite realizar c√°lculos y consolidaciones entre datos de distintas dimensiones, creando modelos que no presentan limitaciones conceptuales ni f√≠sicas, presentando y visualizando la informaci√≥n de forma flexible, esto es, en diferentes formatos.

Los sistemas OLAP est√°n basados, generalmente, en sistemas o interfaces multidimensionales que proporcionan facilidades para la transformaci√≥n de los datos, permitiendo obtener nuevos datos m√°s combinados y agregados que los obtenidos mediante las consultas simples realizadas por OLTP. Al contrario que en OLTP, las unidades de trabajo de OLAP son m√°s complejas que en OLTP y consumen m√°s tiempo.

Finalmente, en cuanto a la visualizaci√≥n de los mismos, los sistemas OLAP permiten la visualizaci√≥n y el an√°lisis multidimensional a partir de diferentes vistas de los datos, presentando los resultados en forma matricial y con mayores posibilidades est√©ticas y visuales. La tabla 1.1 muestra un resumen con las principales diferencias entre los sistemas **OLTP y OLAP**.

| | **Bases de datos relacionales(OLTP)** | **Soluciones Business Intelligence(OLAP)** |
| :-- | :--: | :--: |
| **Concepto** | Sistema de procesamiento de transacciones en l√≠nea | Sistema de recuperaci√≥n y an√°lisis de datos en l√≠nea |
| **Funciones** | Gesti√≥n de transacciones: inserci√≥n, actualizaci√≥n, eliminaci√≥n... | An√°lisis de datos para dar soporte a la toma de decisiones |
| **Procesamiento** | Transacciones cortas | Procesamientos de an√°lisis complejos |
| **Tiempo** | Las transacciones requieren poco tiempo de ejecuci√≥n | Los an√°lisis requieren mayor tiempo de ejecuci√≥n |
| **Consultas** | Simples, utilizando operadores b√°sicos tradicionales | Complejas, permitiendo analizar los datos desde m√∫ltiples dimensiones |
| **Visualizaci√≥n** | B√°sica. Muestra los datos en forma tabular | Muestra los datos en forma matricial. Mayores posibilidades gr√°ficas |

_Tabla 1.1: Tabla resumen y comparativa entre OLTP y OLAP_

‚ùóPor tanto, un **almac√©n de datos**, m√°s conocido por el t√©rmino ***data warehouse*** (en ingl√©s), es una soluci√≥n de **business intelligence** que combina tecnolog√≠as y componentes con el objetivo de ayudar al uso estrat√©gico de los datos por parte de una organizaci√≥n. Esta soluci√≥n debe proveer a la empresa, de forma integrada, de capacidad de almacenamiento de una gran cantidad de datos as√≠ como de herramientas de an√°lisis de los mismos que, frente al procesamiento de transacciones, permita transformar los datos en informaci√≥n para ponerla a disposici√≥n de la organizaci√≥n y optimizar el proceso de toma de decisiones.

_[ver presentaci√≥n BDA1.5](https://moodle.iesgrancapitan.org/pluginfile.php/57450/mod_folder/content/0/BDA_UD1_05.pdf?forcedownload=1)_
### 1.4.2 Bases de datos documentales u orientadas a documentos

La gran variedad y heterogeneidad en los tipos de datos almacenados y procesados en los √∫ltimos a√±os ha puesto sobre la mesa la cuesti√≥n de si las bases de datos relacionales son el modelo m√°s √≥ptimo para trabajar con seg√∫n qu√© tipos de datos. Como alternativa a ellas, en los √∫ltimos a√±os han proliferado las bases de datos NoSQL.


**NoSQL** es el t√©rmino utilizado para referirse a un tipo de bases de datos que permiten almacenar y gestionar tipos de datos que tradicionalmente han sido dif√≠ciles de gestionar por parte de las bases de datos relacionales. As√≠ pues, NoSQL hace referencia a **bases de datos documentales, bases de datos orientadas a grafos, buscadores, etc**. En contraposici√≥n a las bases de datos relacionales, las NoSQL se caracterizan principalmente por:
 - **Independencia del esquema**: Al contrario que en las bases de datos relacionales, no es necesario dise√±ar un esquema para definir los tipos y estructura de los datos almacenados, permitiendo acortar el tiempo de desarrollo y facilitando las modificaciones de la estructura interna de la base de datos.
  
 - **No relacionales**: El concepto de relaci√≥n de las bases de datos relacionales no existe en NoSQL. Por tanto, se trabaja con datos que no est√°n normalizados, lo cual aporta flexibilidad en relaci√≥n a los tipos y estructuras de datos que pueden ser almacenados.
  
 - **Distribuidas**: La cantidad de datos almacenados requiere de su almacenamiento en m√∫ltiples servidores, ya que un √∫nico servidor por potente que sea no podr√° procesar en tiempos razonables tal cantidad de informaci√≥n. Este hecho permite utilizar hardware sencillo, ya que al utilizar m√∫ltiples servidores no es necesario que todos ellos tengan grandes prestaciones.

Las **bases de datos documentales** trabajan con documentos, entendidos como una estructura jer√°rquica de datos que, a su vez, puede contener subestructuras. En una primera aproximaci√≥n, es f√°cil pensar en que estos documentos pueden ser documentos de Microsoft Word, documentos pdf, p√°ginas web... Las bases de datos documentales pueden, efectivamente, trabajar con estos tipos de documentos. Sin embargo, el t√©rmino documento en este contexto posee un mayor nivel de abstracci√≥n.

üîñ Los **documentos** pueden consistir en datos binarios o texto plano. Es posible que se traten de datos semiestructurados, cuando aparecen en formatos como **JavaScript Object Notation (JSON)** o **Extensible Markup Language (XML)**. Por √∫ltimo, tambi√©n pueden ser datos estructurados conforme a un modelo de datos particular como, por ejemplo, **XML Schema Definition (XSD)**.

üîñ Actualmente, **XML y JSON** son los formatos de intercambio de datos m√°s utilizados en el desarrollo de aplicaciones web. Sin embargo, existen importantes diferencias entre ellos: XML es una extensi√≥n del lenguaje **Standard Generalized Markup Language (SGML)** el cual es un lenguaje que permite la creaci√≥n, organizaci√≥n y etiquetado de documentos. Por su parte, JSON es una extensi√≥n del lenguaje **JavaScript**. XML tiene una notaci√≥n m√°s pesada que JSON, siendo este √∫ltimo un lenguaje m√°s ligero que admite tipos de datos y matrices. Por su parte, XML no proporciona tipos ni estructuras de datos, sino que contiene un conjunto de reglas que, mediante el uso de atributos y elementos, permite codificar un documento. Finalmente, JSON es un lenguaje orientado a datos mientras que XML es un lenguaje orientado a documentos. La tabla 1.2 muestra una comparativa de estos y otros aspectos de ambos lenguajes.

| | **XML** | **JSON** |
| :-- | :--: | :--: |
| **Lenguaje fuente** | SGML | JavaScript |
| **Tipo Lenguaje** | Orientado a datos | Orientado a documentos |
| **Notaci√≥n** | Pesada | Ligera |
| **Etiquetas inicio y fin** | S√≠ | No |
| **Comentarios** | S√≠ | No |
| **Espacios de nombres** | S√≠ | No |
| **Soporte tipo de datos** | No | S√≠ |

_Tabla 1.2: Tabla comparativa entre XML y JSON_

üîñ En **XML**, la estructura principal de un documento est√° formada por dos elementos: el **pr√≥logo** (opcional) y el **cuerpo**. El pr√≥logo contiene a su vez dos partes: la declaraci√≥n XML que establece la versi√≥n del lenguaje, el tipo de codificaci√≥n y si se trata de un documento aut√≥nomo y la declaraci√≥n del tipo de documento. El cuerpo, por su parte, contiene la informaci√≥n del documento

üîñ Supongamos que Carlos ha enviado un mensaje de whatsapp a Javier dici√©ndole que han quedado con los compa√±eros de trabajo a las diez de la noche en la puerta del Sol. Un **documento XML** que representa este mensaje como un documento, podr√≠a ser el mostrado en el listado 1.

```xml
<?xml version="1.0" encoding="ISO-8859-1"?>
<whatsapp>
  <para> Javier </para>
  <de> Carlos </de>
  <titulo> Quedada </titulo>
  <contenido> A las 22:00 pm en la puerta del sol </contenido>
</whatsapp>
```
_Listado 1: Quedada en la puerta del sol_

üîñ El listado 1 incluye en la primera l√≠nea el **pr√≥logo** del documento, definiendo la versi√≥n y el tipo de codificaci√≥n utilizada. A partir de la segunda l√≠nea, se define el **cuerpo** del documento que contiene, mediante etiquetas de apertura <>y cierre </>, los distintos atributos de los que se compone el documento.

_[ver presentaci√≥n BDA1.6](https://moodle.iesgrancapitan.org/pluginfile.php/57450/mod_folder/content/0/BDA_UD1_06.pdf?forcedownload=1)_

„ÄΩÔ∏è En JSON, la sintaxis del lenguaje **tiene las mismas reglas que el lenguaje JavaScript**, del cual proviene. Sin embargo, los archivos JSON deben cumplir tambi√©n otras reglas sint√°cticas adicionales.

 - En primer lugar, un archivo JSON representar√° o bien un **objeto**, es decir, una tupla de pares clave-valor o bien una **colecci√≥n de elementos**, es decir, un vector o array.
 - Por otra parte, los archivos JSON que representan objetos comienzan con una llave de inicio { y terminan con una llave de cierre }. Cuando se representa un vector, sus elementos se encierran entre corchetes [].
 - Las **cadenas y nombres de atributos** del objeto deber√°n encerrarse entre comillas, as√≠ como todos los nombres de los atributos del objeto, separ√°ndose cada elemento del siguiente con una coma (,) no habiendo una coma despu√©s del √∫ltimo elemento.

„ÄΩÔ∏è As√≠ pues, si se pretende representar en formato JSON el mensaje que ha enviado Carlos a Javier, el fichero JSON resultante ser√≠a el mostrado en el listado 2. Este fichero define un **objeto JSON** que contiene una serie de atributos entrecomillados cuyo valor asociado son cadenas de caracteres que, por tanto, tambi√©n van entrecomilladas.

```json
{
  "para": "Javier",
  "de": "Carlos",
  "titulo": "Quedada",
  "contenido": "A las 22:00 pm en la puerta del sol"
}
```
_Listado 2: Quedada en la puerta del sol_

!!! note 

    üîñ **Existen en la web m√∫ltiples aplicaciones online que permiten convertir archivos XML en JSON y viceversa** „ÄΩÔ∏è. En sucesivos cap√≠tulos, se profundizar√° m√°s sobre la sintaxis de estos dos lenguajes as√≠ como la equivalencia entre los mismos a la hora de definir documentos que ser√°n tratados posteriormente por una base de datos documental. Tambi√©n se describir√°n las tecnolog√≠as m√°s utilizadas en este √°mbito, haciendo especial √©nfasis en **MongoDB**, uno de los sistemas de bases de datos NoSQL orientado a documentos m√°s utilizado a d√≠a de hoy.


_[ver presentaci√≥n BDA1.7](https://moodle.iesgrancapitan.org/pluginfile.php/57450/mod_folder/content/0/BDA_UD1_07.pdf?forcedownload=1)_
### 1.4.3 Bases de datos sobre grafos

Tal y como se expuso anteriormente, en los √∫ltimos a√±os han aparecido nuevos tipos de datos como aquellos que vienen dados en forma de **grafo**. Algunos de estos datos son los provenientes de interacciones en **redes sociales, datos geogr√°ficos expresados en forma de mapas, etc**.

Un **grafo** es un ente matem√°tico compuesto por un conjunto de **nodos o v√©rtices** y un conjunto de **enlaces o aristas**. Matem√°ticamente puede ser expresado por medio de la ecuaci√≥n siguiente

    G = {V, E}


Donde V representa el conjunto de nodos o v√©rtices y E representa el conjunto de enlaces o aristas. As√≠ pues, sea el grafo de la figura 4 que representa un conjunto de ciudades conectadas por autov√≠as, el conjunto V de nodos ser√≠a V = {La Coru√±a, Madrid, San Sebasti√°n, Barcelona, Valencia, Sevilla, C√°diz}, mientras que el conjunto de enlaces E vendr√≠a dado por

    E = {A-1, A-2, A-3, A-4, A-4-I, A-4-II, A-6, A-7}

![figura1.4][figura1.4]

_Figura 1.4: Grafo que representa las principales autov√≠as de Espa√±a_

Una **base de datos orientada a grafos** es, por tanto, un sistema de bases de datos que implementa m√©todos de creaci√≥n, lectura, actualizaci√≥n y eliminaci√≥n de datos en un modelo expresado en forma de grafo. Existen dos aspectos fundamentales en este tipo de sistemas: el primero de ellos hace referencia al **almacenamiento de los datos**. En una base de datos orientada a grafos, los datos pueden almacenarse siguiendo el modelo relacional, lo que implica mapear la estructura del grafo a una estructura relacional, o bien, almacenarse de forma **nativa** utilizando modelos de datos propios para almacenar estructuras de tipo grafo. La ventaja de mapear los grafos a una estructura relacional radica en que la gesti√≥n y consulta de los datos se realizar√° de forma tradicional a trav√©s de un backend conocido como, por ejemplo, MySQL. Por su parte, la ventaja del almacenamiento nativo de grafos radica es que existen modelos de datos e implementaciones que aseguran y garantizan el buen rendimiento y la escalabilidad del sistema.

El segundo aspecto importante es el **procesamiento de los datos**. En este sentido, tambi√©n es posible distinguir el procesamiento **no nativo** de los grafos, lo cual implica el tratamiento de estos datos siguiendo las t√©cnicas tradicionales utilizadas en los lenguajes de modificaci√≥n de datos de las bases de datos relacionales, o el procesamiento **nativo** de los datos de grafos, el cual es beneficioso porque optimiza los recorridos del grafo cuando se realizan consultas aunque, en ocasiones, invierta demasiado tiempo y memoria en consultas que no requieren de recorridos complejos.

Si bien es cierto que **cualquier dominio puede ser modelado como un grafo**, esta no es una raz√≥n de peso como para cambiar o migrar de un esquema y modelo de datos bien conocido e investigado, como el esquema relacional, a un modelo orientado a grafos. Sin embargo, la motivaci√≥n para requerir de sistemas de bases de datos espec√≠ficos, orientados a trabajar con este tipo de datos, radica en tres aspectos principales:

  - ‚ö´ **Rendimiento**: Los sistemas de bases de datos orientados a grafos optimizan el rendimiento de las consultas sobre este tipo de datos con respecto a las bases de datos relacionales. Si bien es cierto que las consultas en el modelo relacional se vuelven m√°s complejas y el rendimiento disminuye a medida que el conjunto de datos crece, esto no es as√≠ **cuando se trabaja con grafos, donde complejidad y rendimiento permanecen constantes**. Esto es as√≠, ya que las consultas se localizan en una porci√≥n del grafo y, por tanto, solo es necesario explorar la parte del grafo afectada para resolver la consulta.

  - ‚ö´ **Flexibilidad**: Los sistemas de bases de datos orientados a grafos son m√°s flexibles que los sistemas de bases de datos relacionales. Mientras que los primeros requieren la modelizaci√≥n exhaustiva a priori de todo el dominio, esto no es necesario en los segundos, donde **la naturaleza aditiva de los grafos** permite a√±adir nuevos nodos, relaciones, etiquetas y subgrafos a uno dado **sin necesidad de modificar todo el modelo de datos**, facilitando la implementaci√≥n y reduciendo el riesgo a corromper el modelo de datos. 
  - ‚ö´ **Agilidad**: A partir de las dos caracter√≠sticas anteriores, es posible deducir que el trabajo con sistemas de bases de datos orientados a grafos es m√°s √°gil que la gesti√≥n de estos datos a trav√©s de sistemas de bases de datos relacionales. Esta r√°pida gesti√≥n permitir√° utilizar tecnolog√≠a alineada con las nuevas metodolog√≠as de **desarrollo de software √°gil**, permitiendo dise√±ar y desarrollar software que utilice este tipos de datos.

Existen distintos lenguajes de marcado de grafos, a partir de los cuales es posible generar archivos con formato de grafo para ser tratados por una base de datosde este tipo. Algunos de los lenguajes m√°s utilizados **son GraphML, eXtensibleGraph Markup and Modeling Language (XGMML), Graph Exchange Language (GXL) o Graph Modelling Language (GML)**, entre otros. La mayor√≠a deellos son variantes o extensiones del lenguaje XML para el modelado de grafos.


En la actualidad, **GraphML** es uno de los lenguajes m√°s extendidos para el modelado de datos en forma de grafo. Se trata de un lenguaje sencillo, general, extensible y robusto que est√° compuesto por un n√∫cleo del lenguaje que define las propiedades estructurales del grafo y un mecanismo flexible de extensiones que permite a√±adir informaci√≥n espec√≠fica del mismo. La notaci√≥n es muy similar a XML y se profundizar√° en ella en cap√≠tulos posteriores. A modo de ejemplo, el grafo mostrado en la [figura 1.4][figura1.4] podr√≠a representarse en GraphML seg√∫n se muestra en el siguiente listado.


```xml
<graph id="Grafo_Autovias" edgedefault="undirected">
  <node id="La Coru√±a"/>
  <node id="San Sebasti√°n"/>
  <node id="Madrid"/>
  <node id="Barcelona"/>
  <node id="Valencia"/>
  <node id="Sevilla"/>
  <node id="Cadiz"/>
  <edge id = "A-6" source="La Coru√±a" target="Madrid"/>
  <edge id = "A-1" source="Madrid" target="San Sebasti√°n"/>
  <edge id = "A-2" source="Madrid" target="Barcelona"/>
  <edge id = "A-7" source="Barcelona" target="Valencia"/>
  <edge id = "A-3" source="Madrid" target="Valencia"/>
  <edge id = "A-4" source="Madrid" target="Sevilla"/>
  <edge id = "A-4-I" source="Sevilla" target="C√°diz"/>
  <edge id = "A-4-II" source="Madrid" target="C√°diz"/>
</graph>
```
_Listado 3: Grafo Autov√≠as_

Como se puede apreciar en el fragmento de c√≥digo, en primer lugar se define un grafo cuyo identificador es Grafo_Autov√≠as. El tipo de aristas que incluye este grafo son aristas **no dirigidas**, puesto que los enlaces del grafo no presentan flechas que indiquen direcci√≥n. Por tanto, los enlaces son bidireccionales. En caso de definir un grafo dirigido, el valor del atributo edgedefault ser√≠a directed. A continuaci√≥n, se definen los distintos nodos que contendr√° el grafo y despu√©s las aristas o enlaces, definiendo el identificador de cada una de ellas as√≠ como su origen y destino. Al tratarse de un grafo no dirigido, origen y destino son intercambiables, no siendo as√≠ en caso de que se trate de un **grafo dirigido**.

Los sistemas de bases de datos orientados a grafos han proliferado mucho en los √∫ltimos a√±os, existiendo numerosas tecnolog√≠as que dan soporte a ellos, como pueden ser **Microsoft Infinite Graph, Titan, OrientDB, FlockDB, AllegroGraph** o ***Neo4j*** que se estudiar√° con m√°s profundidad posteriormente.

_[ver presentaci√≥n BDA1.8](https://moodle.iesgrancapitan.org/pluginfile.php/57450/mod_folder/content/0/BDA_UD1_08.pdf?forcedownload=1)_









[figura1.1]: images/Figura1.1.jpg "Figura 1: Relaci√≥n entre datos, informaci√≥n y conocimiento en el proceso de toma de decisiones"
[figura1.2]: images/Figura1.2_Las%20tres%20Vs%20del%20big%20data.jpg "Las tres Vs del big data"
[figura1.3]: images/Figura1.3_Las%20ocho%20Vs%20del%20big%20data.jpg "Las ocho Vs del big data"
[figura1.4]: images/Figura1.4_Grafo.jpg "Grafo que representa las principales autov√≠as de Espa√±a"



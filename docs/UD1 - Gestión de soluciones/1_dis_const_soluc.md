# UD 1 Gesti√≥n de Soluciones - Dise√±o y Construcci√≥n de Soluciones

## 1. Introducci√≥n de los datos al conocimiento

El **dato** es una representaci√≥n sint√°ctica, generalmente num√©rica, que puede manejar un dispositivo electr√≥nico - normalmente un ordenador - sin significado por s√≠ solo. Sin embargo, el dato es a su vez el ingrediente fundamental y el elemento de entrada necesario en cualquier sistema y/o proceso que pretenda extraer informaci√≥n o conocimiento sobre un dominio determinado. En este sentido, 7 es un dato, como tambi√©n lo es œÄ o como son los t√©rminos aprobado o suspenso.

Por su parte, la **informaci√≥n** es el dato interpretado, es decir, el dato con significado. Para obtener informaci√≥n, ha sido necesario un proceso en el que, a partir de un dato como elemento de entrada, se realice una **interpretaci√≥n** de ese dato que permita obtener su significado, es decir, informaci√≥n a partir de √©l. La informaci√≥n es tambi√©n el elemento de entrada y de salida en cualquier proceso de toma de decisiones. Partiendo de los datos del ejemplo anterior, informaci√≥n obtenida a partir de los mismos puede ser: El 7 es un n√∫mero primo, œÄ es una constante cuyo valor es 3, 141592653..., Mar√≠a ha aprobado el examen de conducir, Pablo est√° suspenso en matem√°ticas.

A partir de informaci√≥n, es posible construir conocimiento. El **conocimiento** es informaci√≥n aprendida, que se traduce a su vez en reglas, asociaciones, algoritmos, etc. que permiten resolver el proceso de toma de decisiones. As√≠ pues, la informaci√≥n obtenida a partir de los datos permite generar conocimiento, es decir, aprender. El conocimiento no es est√°tico, como tampoco lo es siempre el aprendizaje. Aprender, construir conocimiento, implica necesariamente contrastar y validar el conocimiento construido con nueva informaci√≥n que permita, a su vez, guiar el aprendizaje y construir conocimiento nuevo. Siguiendo con los ejemplos anteriores, el conocimiento que permite obtener que el 7 es un n√∫mero primo puede ser el _algoritmo de Erat√≥stenes_. Por otra parte, el conocimiento que permite obtener el valor del n√∫mero œÄ puede extraerse de los resultados de los trabajos de _Jones, Euler o Arqu√≠medes_, mientras que el aprobado de Mar√≠a en el examen de conducir y el suspenso de Pablo en matem√°ticas, se pueden obtener de la regla que en una escala de diez asigna el aprobado a notas mayores o iguales que 5 y el suspenso a notas menores.

<figure style="align: center;">
    <img src="images/Figura1.1.jpg">
    <figcaption>Figura 1.1: Relaci√≥n entre datos, informaci√≥n y conocimiento en el proceso de toma de decisiones. (Fuente: UCLM)</figcaption>
</figure>

Por tanto, datos, informaci√≥n y conocimiento est√°n estrechamente relacionados entre s√≠ y dirigen cualquier proceso de toma de decisiones  La [figura1.1][figura1.1] muestra la relaci√≥n entre datos, informaci√≥n y conocimiento, en un proceso gen√©rico de **toma de decisiones**. M√°s concretamente, en el ejemplo del suspenso de Pablo en matem√°ticas, el proceso de toma de decisi√≥n acerca de la calificaci√≥n de Pablo se estructurar√≠a de la siguiente forma:

1. El profesor corrige el examen de Pablo, que ha sacado un 3. Esta calificaci√≥n, por s√≠ sola, es simplemente un dato.

2. A continuaci√≥n, el profesor calcula la calificaci√≥n final de Pablo, en base a la nota del examen, sus trabajos y pr√°cticas de laboratorio. _La nota final de Pablo es un 4_. Esto √∫ltimo es informaci√≥n.

3. ¬øHa aprobado Pablo? La informaci√≥n de entrada al proceso de decisi√≥n es su calificaci√≥n final de 4 puntos, obtenida en el paso anterior. El conocimiento del profesor sobre el sistema de calificaci√≥n le indica que una nota menor a 5 puntos se corresponde con un suspenso y, en caso contrario, con un aprobado.

4. La informaci√≥n de salida tras este proceso de decisi√≥n es que _Pablo est√° suspenso en matem√°ticas_.

!!! question 

    Siguiendo el ejemplo anterior ¬øC√≥mo se produce el proceso de toma de decisiones para determinar si un n√∫mero es primo?

Aunque se trate de un ejemplo trivial, la importancia del proceso de toma de decisiones no lo es. En **marketing**, por ejemplo, se analizan bases de datos de clientes para identificar distintos grupos e intentar predecir el comportamiento de estos. En el mundo de las **finanzas**, las inversiones realizadas por grandes empresas responden a un proceso complejo de toma de decisiones donde los datos son el eje fundamental de este proceso. En **medicina**, existe una gran cantidad de sistemas de ayuda a la decisi√≥n que permiten a los doctores contrastar y validar sus diagn√≥sticos de forma precoz. En definitiva, no hay √°rea de conocimiento ni √°mbito de aplicaci√≥n que escape al proceso de toma de decisiones.

## 2. La carrera entre los datos y la tecnolog√≠a

Que los datos son el elemento fundamental en cualquier proceso y/o sistema de **toma de decisiones** no es algo nuevo. Sin embargo, los datos no siempre han estado al alcance de los expertos y no siempre ha sido posible ni sencillo procesarlos seg√∫n las necesidades concretas de cada caso de aplicaci√≥n.

La informaci√≥n, por tanto, siempre ha sido poder y el gran reto ha sido y sigue siendo extraer informaci√≥n a partir de datos para generar conocimiento. Para ello, es necesario contar con dos factores que deben estar alineados: **datos y tecnolog√≠a**.

Obtener **datos** no ha sido siempre una tarea f√°cil. Esto es debido principalmente a que la gran cantidad de sensores disponibles en la actualidad, que permiten registrar magnitudes de cualquier proceso, no exist√≠a como a d√≠a de hoy. Adem√°s, los sensores existentes en esta √©poca (finales del siglo XX y comienzos del siglo XXI) no estaban ampliamente extendidos, ya que sus prestaciones estaban lejos de las que ofrecen hoy y sus precios no estaban al alcance de cualquier usuario. Por tanto, los procesos que se monitorizaban y de los cuales se recog√≠an datos eran, sobretodo, procesos industriales realizados en grandes empresas. Por todos estos motivos, tradicionalmente se recurr√≠a a **modelos de simulaci√≥n** que, a trav√©s de la implementaci√≥n de un modelo matem√°tico, permit√≠an generar datos realistas de un proceso.

Los datos generados mediante simulaci√≥n son conocidos como **datos sint√©ticos** mientras que los datos provenientes de las lecturas de un sensor se conocen como **datos reales**.

Pero con los datos no es suficiente. Es necesario tambi√©n contar con la tecnolog√≠a necesaria para su procesamiento. Generar, almacenar y procesar todos estos datos no es una tarea trivial, y plantea una serie de problemas tecnol√≥gicos a resolver.

 - Primer problema tecnol√≥gico a resolver, el **almacenamiento**. Algunas soluciones propuestas pasan por los **sistemas de informaci√≥n distribuida**, entendidos como un conjunto de ordenadores separados f√≠sicamente y conectados en red destinados al almacenamiento de datos o por los **sistemas de informaci√≥n en la nube**, que permiten adquirir espacio de almacenamiento en servidores privados, dejando la gesti√≥n de estos servidores en manos del proveedor.
 - El segundo problema tecnol√≥gico es el **procesamiento** de los datos almacenados. Este aspecto cobra especial relevancia en funci√≥n del caso de aplicaci√≥n, pudiendo distinguirse entre procesamiento on-line (en l√≠nea/**stream**) y procesamiento off-line (fuera de l√≠nea/**batch**).
   
   * üíª En el caso del **procesamiento on-line/stream processing**, los datos son procesados a medida que son generados, ya que se requiere una respuesta en tiempo real. Por ejemplo, en un sistema de control del tr√°fico que permite regular los sem√°foros en funci√≥n del tr√°fico actual, el sistema debe regular el sem√°foro a medida que se van generando e interpretando los datos del tr√°fico en un instante de tiempo dado.
   * ‚ùé Por otra parte, en el caso del **procesamiento off-line/batch processing**, no es necesario que los datos se procesen a medida que se generan. Por ejemplo, en un sistema de detecci√≥n del fraude bancario, comprobar si un cliente ha realizado alg√∫n movimiento fraudulento es una tarea que puede llevarse a cabo off-line, por ejemplo, haciendo un an√°lisis de los movimientos del cliente en un momento dado, sin tener por qu√© diagnosticar cada movimiento que este va realizando.

En este sentido, la **computaci√≥n distribuida**, en donde m√∫ltiples m√°quinas realizan el procesamiento optimizando el rendimiento o la **computaci√≥n en la nube**, que permite adquirir recursos de procesamiento al igual que se puede adquirir espacio de almacenamiento, son dos soluciones al problema del procesamiento.

Otras alternativas son la **programaci√≥n paralela** y la **programaci√≥n multi-procesador**, que permiten, respectivamente, aprovechar el paralelismo de m√∫ltiples hilos de ejecuci√≥n dentro de un procesador y realizar el procesamiento dividi√©ndolo en m√∫ltiples hilos en diferentes procesadores

!!! question 

    Piensa en procesos cotidianos que requieran un procesamiento on-line y en otros que requieran un procesamiento off-line.

‚è≥ En la actualidad, la proliferaci√≥n de una gran cantidad de sensores con altas prestaciones y precios asequibles que permiten monitorizar y generar datos sobre cualquier proceso ha supuesto un **incremento exponencial en la cantidad de datos generados**. Es posible monitorizar casi cualquier proceso, incluyendo los dom√©sticos como el consumo el√©ctrico de un hogar, la presencia dentro del mismo o procesos cotidianos como la actividad f√≠sica, entre otros muchos. Hoy, los datos llevan la delantera en la carrera entre datos y tecnolog√≠a. Si bien es cierto que la tecnolog√≠a ha experimentado grandes avances en los √∫ltimos a√±os, la cantidad de datos generada no deja de crecer. Esto supone un **reto permanente para la tecnolog√≠a**, que sigue evolucionando a nivel hardware con la aparici√≥n de arquitecturas con mayores posibilidades de procesamiento, almacenamiento y a nivel software, con la aparici√≥n de modelos de programaci√≥n que optimizan el procesamiento de los datos.


## 3. Los datos: los de ayer y los de hoy

Al igual que la tecnolog√≠a ha ido evolucionando para dar respuesta a la ingente cantidad de datos que ha comenzado a generarse, estos √∫ltimos tambi√©n han experimentado una gran evoluci√≥n. Esta evoluci√≥n, o revoluci√≥n, no est√° √∫nicamente relacionada con la **cantidad** de datos (como se expuso en el anterior apartado) sino tambi√©n con el **tipo** y el **formato** de los mismos.

üíæ Tradicionalmente, el tipo y formato de datos con el que se ha trabajado para extraer informaci√≥n y conocimiento a partir de ellos era ciertamente **limitado**. En muchas ocasiones se trataba de ficheros de datos estructurados de forma tabular, donde cada fila del conjunto de datos representaba una instancia del mismo y cada columna una variable o atributo de la instancia. El formato de archivo que se manejaba sol√≠an ser **formatos de hojas de c√°lculo** (.xlsx, .ods, .numbers etc) o **ficheros separados por comas** (.csv). Muy pocos eran los procesos en los que se trabajaba con otros tipos de datos como texto, im√°genes, audio e incluso v√≠deos, ya que los formatos de estos tipos de datos eran limitados hace unos a√±os, su procesamiento m√°s complejo y la tecnolog√≠a para ello a√∫n en desarrollo.

Aunque a d√≠a de hoy tambi√©n se sigue trabajando con archivos de datos en forma de hojas de c√°lculo y/o archivos tradicionales para generar conocimiento a partir de ellos, las posibilidades actuales son pr√°cticamente **ilimitadas**.

  - ‚úèÔ∏è En cuanto al _texto_, las t√©cnicas de inteligencia artificial y procesamiento del lenguaje natural hacen posible la extracci√≥n de conocimiento a partir de **grandes vol√∫menes de textos**, que pueden provenir de p√°ginas web, archivos .pdf, redes sociales, etc.
  
  - üìπ El desarrollo de hardware con mejores prestaciones y los nuevos modelos de programaci√≥n permiten procesar en la actualidad **grandes cantidades de im√°genes, audios y v√≠deos** con una gran variedad de t√©cnicas de inteligencia artificial en tiempos razonables.

  - ‚ö´ Finalmente, han aparecido nuevos tipos y formatos de datos, como por ejemplo, aquellos datos generados a partir de **grafos**, los cuales se tratar√°n en pr√≥ximas secciones y cap√≠tulos con m√°s detenimiento. Estos datos se corresponden, por ejemplo, con datos geogr√°ficos obtenidos a partir de mapas como los generados en aplicaciones como Google Maps u Open Street Maps o datos de seguimiento y actividad en redes sociales de gran valor en campa√±as publicitarias entre otros muchos.

!!! question 

    Haz una b√∫squeda y elabora un listado con distintos tipos de datos y los formatos de almacenamiento m√°s utilizados con los que se trabaja en ciencia de datos y big data.

Los diferentes tipos y formatos de datos, los de ayer y los de hoy, son la materia b√°sica fundamental en cualquier proceso de extracci√≥n de informaci√≥n y de conocimiento. Despu√©s, las metodolog√≠as empleadas para ello y arquitecturas hardware sobre las que se realice el procesamiento de los mismos, permitir√°n definir **procesos y metodolog√≠as de big data**, aplicadas a un √°mbito concreto.


## 4. Soluciones Big Data

En esta nueva era tecnol√≥gica en la que nos hayamos inmersos, a diario se generan enormes cantidades de datos, del orden de **petabytes** (m√°s de un mill√≥n de gigabytes) **en muy cortos peri√≥dos de tiempo**. Hoy en d√≠a, cualquier dispositivo como puede ser un reloj, un coche, un smartphone, etc est√° conectado a Internet generando, enviando y recibiendo una gran cantidad de datos. Tanto es as√≠, que se estima que el 90 % de los datos disponibles en el mundo ha sido generado en los √∫ltimos a√±os. Sin lugar a dudas, esta y las pr√≥ximas generaciones ser√°n las generaciones del big data.

Esta realidad descrita anteriormente demanda la capacidad de enviar y recibir datos e informaci√≥n a gran velocidad, as√≠ como la capacidad de almacenar tal cantidad de datos y procesarlos en tiempo real. As√≠ pues, la gran cantidad de datos disponibles junto con las herramientas, tanto hardware como software, que existen a disposici√≥n para analizarlos se conoce como ***big data***.

‚úåÔ∏è No existe una definici√≥n precisa del t√©rmino **big data**, ni tampoco un t√©rmino en castellano que permita denominar este concepto. A veces se usan en castellano los t√©rmino _datos masivos_ o _grandes vol√∫menes de datos_ para hacer referencia al big data. Por este motivo, a menudo el concepto de big data es definido en funci√≥n de las caracter√≠sticas que poseen los datos y los procesos que forman parte de este nuevo paradigma de computaci√≥n. Esto es lo que se conoce como ‚úåÔ∏è **las Vs del big data** ‚úåÔ∏è.

Algunos autores coinciden en que big data son datos cuyo **volumen** es demasiado grande como para procesarlos con las tecnolog√≠as y t√©cnicas tradicionales, requiriendo nuevas arquitecturas hardware, modelos de programaci√≥n y algoritmos para su procesamiento. Adem√°s, se trata de datos que se presentan en una gran **variedad** de estructuras y formatos: datos sint√©ticos, provenientes de sensores, num√©ricos, textuales, im√°genes, audio, v√≠deo... Finalmente, se trata de datos que requieren ser procesados a gran **velocidad** para poder extraer valor y conocimiento de ellos. Esta concepci√≥n se conoce como las tres Vs del big data (ver [figura1.2][figura1.2]).

<figure style="align: center; width: 600px;">
    <img src="images/Figura1.2_Las_tres_Vs_del_big_data.png">
    <figcaption>Figura 1.2: Definici√≥n de big data en base a ‚ÄúLas tres Vs del big data". (Fuente: Researchgate)</figcaption>
</figure>


Otros autores ampl√≠an las caracter√≠sticas que han de tener los datos que forman parte del big data, incluyendo ‚Äúotras Vs‚Äù como lo son:

   - ‚úåÔ∏è **Volatilidad**, referida al tiempo durante el cual los datos recogidos son v√°lidos y a durante cu√°nto tiempo deber√°n ser almacenados.
   - ‚úåÔ∏è **Valor**, referido a la utilidad de los datos obtenidos para extraer conocimiento y tomar decisiones a partir de ellos.
   - ‚úåÔ∏è **Validez**, referida a lo precisos que son los datos para el uso que se pretende darles. El uso de datos validados permitir√° ahorrar tiempo en etapas como la limpieza y el preprocesamiento de los datos.
   - ‚úåÔ∏è ***Veracidad***, relacionada con la confiabilidad del origen del cual provienen los datos con los que se trabajar√° as√≠ como la incertidumbre o el ruido que pudiera existir en ellos.
   - ‚úåÔ∏è **Variabilidad**, frente a la variedad de estructuras y formatos, hace referencia a la complejidad del conjunto de datos, es decir, al n√∫mero de variables que contiene. Estas caracter√≠sticas, unidas a las tres Vs descritas anteriormente, se conocen como las ocho Vs del big data (ver [figura1.3][figura1.3]).

<figure style="align: center; width: 600px;">
    <img src="images/Figura1.3_Las_ocho_Vs_del_big_data.svg">
    <figcaption>Figura 1.3: Definici√≥n de big data en base a ‚ÄúLas ocho Vs del big data‚Äù. (Fuente: Linkedin)</figcaption>
</figure>

Dado que no existe una definici√≥n uniforme para el t√©rmino big data, muchos autores definen el t√©rmino en funci√≥n de aquellas caracter√≠sticas que consideran m√°s relevantes, por lo que es com√∫n encontrar ‚Äúlas cinco Vs del big data‚Äù, ‚Äúlas siete Vs del big data‚Äù o ‚Äúlas diez Vs del big data‚Äù seg√∫n cada autor, apareciendo distintos t√©rminos para describir el big data, como tambi√©n pueden ser **visualizaci√≥n** o **vulnerabilidad**, entre otros. 

Son muchas las **soluciones a nivel hardware y software**, que se han propuesto a los problemas derivados del almacenamiento y el procesamiento de big data. A continuaci√≥n, se describen los fundamentos de tres de ellas, las cuales ser√°n desarrolladas a nivel te√≥rico, tecnol√≥gico y pr√°ctico en los siguientes cap√≠tulos.


## 5. Almacenes de datos

üíæ Tradicionalmente hablando, cuando nos referimos a almacenes de datos, podemos hablar de las **bases de datos relacionales** son colecciones de datos integrados, almacenados en un soporte secundario no vol√°til y con redundancia controlada. La definici√≥n de los datos y la estructura de la base de datos debe estar basada en un modelo de datos que permita captar las interrelaciones y restricciones existentes en el dominio que se pretende modelizar. A su vez, un **Sistema Gestor de Bases de Datos (SGBD)** se compone de una colecci√≥n de datos estructurados e interrelacionados (una base de datos) as√≠ como de un conjunto de programas para acceder a dichos datos.

üíæ Las bases de datos tradicionales, siguiendo la definici√≥n anterior, est√°n basadas generalmente en sistemas relacionales u objeto-relacionales. Para el acceso, procesamiento y recuperaci√≥n de los datos, se sigue el modelo **Online Transaction Processing (OLTP)**. Una transacci√≥n es una interacci√≥n completa con un sistema de base de datos, que representa una unidad de trabajo. As√≠ pues, una transacci√≥n representa cualquier cambio que se produzca en una base de datos.

üíæ El modelo OLTP, traducido al castellano como **procesamiento de transacciones en l√≠nea**, permite gestionar los cambios de la base de datos mediante la inserci√≥n, actualizaci√≥n y eliminaci√≥n de informaci√≥n de la misma a trav√©s de transacciones b√°sicas que son procesadas en tiempos muy peque√±os.

üíæ Con respecto a la recuperaci√≥n de informaci√≥n de la base de datos, se utilizan operadores cl√°sicos (concatenaci√≥n, proyecci√≥n, selecci√≥n, agrupamiento...) para realizar consultas b√°sicas y sencillas (realizadas, mayoritariamente, en lenguaje SQL y extensiones del mismo).

üíæ Finalmente, las opciones de visualizaci√≥n de los datos recuperados son limitadas, mostr√°ndose fundamentalmente los resultados de forma tabular y requiriendo un procesamiento adicional y m√°s complejo en caso de querer presentar datos complejos.

üîÅ La revoluci√≥n en la generaci√≥n, almacenamiento y procesamiento de los datos, as√≠ como la irrupci√≥n del **big data**, han puesto a prueba el modelo de funcionamiento, rendimiento y escalabilidad de las bases de datos relacionales tradicionales. En la actualidad, se requiere de soluciones integradas que a√∫nen datos y tecnolog√≠a para almacenar y procesar grandes cantidades de datos con diferentes estructuras y formatos con el objetivo de facilitar la consulta, el an√°lisis y la toma de decisiones sobre los mismos. En este sentido, la **inteligencia de negocio**, m√°s conocida por el t√©rmino ingl√©s **business intelligence**, investiga en el dise√±o y desarrollo de este tipo de soluciones. La inteligencia de negocio puede definirse como ***la capacidad de una empresa de estudiar sus acciones y comportamientos pasados para entender d√≥nde ha estado la empresa, determinar la situaci√≥n actual y predecir o cambiar lo que suceder√° en el futuro, utilizando las soluciones tecnol√≥gicas m√°s apropiadas para optimizar el proceso de toma de decisiones***.

Estas nuevas soluciones requerir√°n un modelo de procesamiento diferente a **OLTP**. Esto es as√≠, ya que el objetivo perseguido por la inteligencia de negocio est√° menos orientado al √°mbito transaccional y m√°s enfocado al √°mbito anal√≠tico. Las nuevas soluciones utilizan el modelo **Online analytical processing (OLAP)**.

La principal diferencia entre OLTP y OLAP estriba en que mientras que el primero es un sistema de procesamiento de transacciones en l√≠nea, el segundo es un sistema de **recuperaci√≥n y an√°lisis** de datos en l√≠nea. Por tanto, OLAP complementa a SQL aportando la capacidad de analizar datos desde distintas variables y dimensiones, mejorando el proceso de toma de decisiones. Para ello, OLAP permite realizar c√°lculos y consolidaciones entre datos de distintas dimensiones, creando modelos que no presentan limitaciones conceptuales ni f√≠sicas, presentando y visualizando la informaci√≥n de forma flexible, esto es, en diferentes formatos.

Los sistemas OLAP est√°n basados, generalmente, en sistemas o interfaces multidimensionales que proporcionan facilidades para la transformaci√≥n de los datos, permitiendo obtener nuevos datos m√°s combinados y agregados que los obtenidos mediante las consultas simples realizadas por OLTP. Al contrario que en OLTP, las unidades de trabajo de OLAP son m√°s complejas que en OLTP y consumen m√°s tiempo.

Finalmente, en cuanto a la visualizaci√≥n de los mismos, los sistemas OLAP permiten la visualizaci√≥n y el an√°lisis multidimensional a partir de diferentes vistas de los datos, presentando los resultados en forma matricial y con mayores posibilidades est√©ticas y visuales. La tabla 1.1 muestra un resumen con las principales diferencias entre los sistemas **OLTP y OLAP**.

<center>

| | **Bases de datos relacionales(OLTP)** | **Soluciones Business Intelligence(OLAP)** |
| :-- | :--: | :--: |
| **Concepto** | Sistema de procesamiento de transacciones en l√≠nea | Sistema de recuperaci√≥n y an√°lisis de datos en l√≠nea |
| **Funciones** | Gesti√≥n de transacciones: inserci√≥n, actualizaci√≥n, eliminaci√≥n... | An√°lisis de datos para dar soporte a la toma de decisiones |
| **Procesamiento** | Transacciones cortas | Procesamientos de an√°lisis complejos |
| **Tiempo** | Las transacciones requieren poco tiempo de ejecuci√≥n | Los an√°lisis requieren mayor tiempo de ejecuci√≥n |
| **Consultas** | Simples, utilizando operadores b√°sicos tradicionales | Complejas, permitiendo analizar los datos desde m√∫ltiples dimensiones |
| **Visualizaci√≥n** | B√°sica. Muestra los datos en forma tabular | Muestra los datos en forma matricial. Mayores posibilidades gr√°ficas |

_Tabla 1.1: Tabla resumen y comparativa entre OLTP y OLAP_
</center>


### 5.1. Sistemas de ayuda a la decisi√≥n


En una empresa u organizaci√≥n, los datos generados a diario son, principalmente, aquellos derivados de las operaciones rutinarias de la empresa. Estos datos, tradicionalmente, se almacenaban en **bases de datos relacionales** y su manipulaci√≥n se correspond√≠a con **transacciones** realizadas sobre la base de datos. Sin embargo, el objetivo de cualquier organizaci√≥n es seleccionar esos datos para realizar estudios y an√°lisis que permitan generar informes que, a su vez, permitan a la empresa **extraer informaci√≥n para tomar decisiones estrat√©gicas** que conduzcan a la organizaci√≥n al √©xito.


El crecimiento exponencial de los datos manejados por una organizaci√≥n ha hecho que los computadores sean las √∫nicas herramientas capaces de procesar estos datos para obtener informaci√≥n y ofrecer ayuda en la toma de decisiones. En este contexto, aparecen los **sistemas de ayuda a la decisi√≥n** o _Decision Support Systems (DSS)_ que ayudan a quienes ocupan puestos de gesti√≥n a tomar decisiones o elegir entre diferentes alternativas. 

!!! info "Sistema de ayuda a la decisi√≥n"

    üìÑ **Sistema de ayuda a la decisi√≥n**: Conjunto de t√©cnicas y herramientas tecnol√≥gicas desarrolladas para procesar y analizar datos para ofrecer soporte en la toma decisiones a quienes ocupan puestos de gesti√≥n o direcci√≥n en una organizaci√≥n. Para ello, el sistema combina los recursos de los gestores junto con los recursos computacionales para optimizar el proceso de toma de decisiones.


Mientras que las bases de datos relacionales han sido tradicionalmente el componente del _back-end_ en el dise√±o de sistemas de ayuda a la decisi√≥n, los almacenes de datos se han convertido en una opci√≥n mucho m√°s competitiva como elemento _back-end_ al mejorar el rendimiento de √©stas.

Los **campos de aplicaci√≥n** de los almacenes de datos no se reducen √∫nicamente al √°mbito empresarial, sino que cubren multitud de dominios como las **ciencias naturales, demograf√≠a, epidemiolog√≠a o educaci√≥n, entre otros muchos**. La propiedad com√∫n a todos estos campos y que hace de los almacenes de datos una adecuada soluci√≥n en estos √°mbitos **es la necesidad de almacenamiento y herramientas de an√°lisis que permitan obtener en tiempos razonables informaci√≥n y conocimiento √∫tiles para mejorar el proceso de toma de decisiones**.


### 5.2. Almacenes de datos: Concepto

La aparici√≥n de los **almacenes de datos** est√° ligada, principalmente, a una serie de retos que es necesario abordar para **convertir los datos transaccionales** con los que trabaja una base de datos relacional en **informaci√≥n para generar conocimiento y dar soporte al proceso de toma de decisiones**

   - **Accesibilidad**: Desde cualquier dispositivo, a cualquier tipo de usuario y a gran cantidad de informaci√≥n que no puede ser almacenada de forma centralizada. La accesibilidad, en este sentido, debe hacer frente al problema de la **escalabilidad** del sistema y de los datos que este maneja.
  
   - **Integraci√≥n**: Referente a la gesti√≥n de datos heterog√©neos, con distintos formatos, y provenientes de distintos √°mbitos de la organizaci√≥n. Una correcta integraci√≥n debe garantizar a su vez la correcci√≥n y completitud de los datos integrados.
  
   - **Consultas mejoradas**: Permitiendo incluir operadores avanzados y dar soporte a herramientas y procedimientos que posibiliten obtener el m√°ximo partido de los datos existentes. De este modo, ser√° posible obtener **informaci√≥n precisa para realizar un an√°lisis eficiente**.
  
   - **Representaci√≥n multidimensional**: Proporciona herramientas para analizar de forma multi-dimensional los datos del sistema, incluyendo datos de **diferentes unidades** de la organizaci√≥n con el objetivo de proporcionar herramientas de **an√°lisis y visualizaci√≥n multi-dimensional** para mejorar el proceso de toma de decisiones.

!!! success "Almac√©n de datos (Data Warehouse)"

    üìö Por tanto, un **almac√©n de datos**, m√°s conocido por el t√©rmino ***data warehouse*** (en ingl√©s), es una soluci√≥n de **business intelligence** que combina tecnolog√≠as y componentes con el objetivo de ayudar al uso estrat√©gico de los datos por parte de una organizaci√≥n. Esta soluci√≥n debe proveer a la empresa, de forma integrada, de capacidad de almacenamiento de una gran cantidad de datos as√≠ como de herramientas de an√°lisis de los mismos que, frente al procesamiento de transacciones, permita transformar los datos en informaci√≥n para ponerla a disposici√≥n de la organizaci√≥n y optimizar el proceso de toma de decisiones.


    üìÑ O bien, m√°s resumidamente, seg√∫n W. Inmon (conocido por ser el ‚Äúpadre‚Äù del concepto de **Almac√©n de datos (Data Warehouse)**): Colecci√≥n de datos orientados a temas, integrados, variante en el tiempo y no vol√°til que da soporte al proceso de toma de decisiones de la direcci√≥n.

Para entender correctamente esta definici√≥n, es necesario ahondar en las caracter√≠sticas que incluye la misma.

- **Orientados a temas**: Es decir, no orientado a procesos (transacciones), sino a entidades de mayor nivel de abstracci√≥n como ‚Äúart√≠culo‚Äù o ‚Äúpedido‚Äù.

- **Integrados**: Almacenados en un formato uniforme y consistente, lo que implica depurar o limpiar los datos para poder integrarlos.

- **Variante en el tiempo**: Asociados a un instante de tiempo (mes, trimestre, a√±o...)

- **No vol√°tiles**: Se trata de datos persistentes que no cambian una vez se incluyen en el almac√©n de datos.

El dise√±o y funcionamiento de los almacenes de datos se basa en el sistema de procesamiento anal√≠tico en-l√≠nea, **OLAP**. Este sistema se encarga del an√°lisis, interpretaci√≥n y toma de decisiones acerca del negocio, en contraposici√≥n a los sistemas de procesamiento de transacciones en l√≠nea, **OLTP**.

As√≠ pues, los sistemas **OLTP est√°n dirigidos por la tecnolog√≠a y orientados a automatizar las operaciones del d√≠a a d√≠a** de la organizaci√≥n, mientras que los sistemas **OLAP est√°n dirigidos por el negocio y proporcionan herramientas para tomar decisiones a largo plazo**, mejorando la estrategia y la competitividad de la organizaci√≥n. La tabla 1.2 muestra una comparativa entre las principales caracter√≠sticas de las bases de datos operacionales (OLTP) y los almacenes de datos (OLAP).

<center>

| Caracter√≠stica | **BBDD Operacionales(OLTP)** | **Almac√©n Datos(OLAP)** |
| -- | :--: | :--: |
| **Objetivo** | Depende de la aplicaci√≥n | Toma de decisiones |
| **Usuarios** | Miles | Cientos |
| **Trabajo con...** | Transacciones predefinidas | Consultas y an√°lisis espec√≠ficos |
| **Acceso** | Lectura y escritura a cientos de registros | Principalmente lecutra. Miles de registros |
| **Datos** | Detallados, num√©ricos y alfanum√©ricos | Agregados, principalmente num√©ricos |
| **Integraci√≥n** | En funci√≥n de la aplicaci√≥n | Basados en temas, con mayor nivel de abstracci√≥n |
| **Calidad** | Medida en t√©rminos de integridad | Medida en t√©rminos de consistencia |
| **Temporalidad Datos** | Solo datos actuales | Datos actuales e hist√≥ricos |
| **Actualizaciones** | Continuas | Peri√≥dicas |
| **Modelo** | Normalizado | Desnormalizado, multidimensional |
| **Optimizaci√≥n** | Para acceso OLTP a parte de la BBDD | Para acceso OLAP a gran parte de la BBDD |

_Tabla 1.2. Diferencias entre BBDD Operacionales y Almacenes de Datos_
</center>

### 5.3 Almacenes de datos: Arquitectura

Las arquitecturas disponibles para el **dise√±o de almacenes de datos** se basan, principalmente, en garantizar que el sistema cumpla una serie de propiedades esenciales para su √≥ptimo funcionamiento

- **Separaci√≥n**: De los datos transaccionales y los datos estrat√©gicos que sirven como punto de partida a la toma de de decisiones.

- **Escalabilidad**: A nivel hardware y software, para actualizarse y garantizar el correcto funcionamiento del sistema a medida que el n√∫mero de datos y usuarios aumenta.

- **Extensiones**: Permitiendo integrar e incluir nuevas aplicaciones sin necesidad de redise√±ar el sistema completo.

- **Seguridad**: Monitorizando el acceso a los datos estrat√©gicos guardados en el almac√©n de datos.

!!! note "Almac√©n de datos"

    üìÑ Las arquitecturas de **almacenes de datos** se clasifican, fundamentalmente, en dos tipos: arquitecturas orientadas a la estructura y arquitecturas orientadas a la empresa.

#### 5.3.1 Arquitecturas orientadas a la estructura

Las arquitecturas orientadas a la estructura reciben su nombre debido a que est√°n dise√±adas poniendo especial √©nfasis en el **n√∫mero de capas y elementos que componen la arquitectura del sistema de almac√©n de datos**. De acuerdo con este criterio, es posible distinguir las siguientes arquitecturas.

***Arquitectura de una capa***

El objetivo principal de esta arquitectura, poco utilizada en la pr√°ctica, es **minimizar la cantidad de datos almacenados eliminando para ello los datos redundantes**. La [figura1.4][figura1.4] muestra un esquema de este tipo de arquitectura. En ella, el almac√©n de datos creado es virtual, existiendo un middleware que interpreta los datos operacionales y ofrece una vista multidimensional de ellos.

**El principal inconveniente** de esta arquitectura es que su simplicidad hace que el sistema **no cumpla la propiedad de separaci√≥n**, ya que los procesos de an√°lisis se realizan sobre los datos operacionales.

<figure style="align: center; width:600px;">
    <img src="images/Figura1.4_Almac√©n_de_datos._Arquitectura_de_una_capa.png">
    <figcaption>Figura 1.4. Almac√©n de datos. Arquitectura de una capa. (Fuente: UCLM)</figcaption>
</figure>


***Arquitectura de dos capas***

Fue dise√±ada con el objetivo de solucionar el problema de la separaci√≥n que presentaba la arquitectura de una capa. Este esquema consigue **subrayar la separaci√≥n entre los datos disponibles y el almac√©n de datos** a trav√©s de los siguientes componentes (ver [figura1.5][figura1.5]:

- **Capa de origen (fuente)**: Se corresponde con los or√≠genes y fuentes de los datos heterog√©neos que se pretenden incorporar al almac√©n de datos.

- **Puesta a punto**: Proceso por el cual se utilizan herramientas de Extracci√≥n, Transformaci√≥n y Carga (ETL) para extraer, limpiar, filtrar, validar y cargar datos en el almac√©n de datos.

- **Capa de almac√©n de datos**: Almacenamiento centralizado de la informaci√≥n en el almac√©n de datos, el cual puede ser utilizado para crear _data marts_ o repositorios de metadatos.

- **An√°lisis**: Conjunto de procesos a partir de los cuales los datos son analizados de forma eficiente y flexible, generando informes y simulando escenarios hipot√©ticos para dar soporte a la toma de decisiones.

!!! info "Data mart"

    üìã **Data mart** es un subconjunto o agregaci√≥n de los datos almacenados en un almac√©n de datos primario que incluye informaci√≥n relevante sobre un √°rea espec√≠fica del negocio.

<figure style="align: center; width:600px;">
    <img src="images/Figura1.5_Almac√©n_de_datos._Arquitectura_de_dos_capas.png">
    <figcaption>Figura 1.5. Almac√©n de datos. Arquitectura de dos capas. (Fuente: UCLM)</figcaption>
</figure>


***Arquitectura de tres capas***

Este tercer tipo de arquitectura incluye una capa llamada de **datos reconciliados** o almac√©n de datos operativos. Con esta capa, los datos operativos obtenidos tras la limpieza y depuraci√≥n son integrados y validados, proporcionando un modelo de datos de referencia para toda la organizaci√≥n.

De este modo, **el almac√©n de datos no se nutre de los datos de origen directamente, sino de los datos reconciliados generados**, los cuales tambi√©n son utilizados para realizar de forma m√°s eficiente tareas operativas, como la realizaci√≥n de informes o la alimentaci√≥n de datos a procesos operativos.

Esta capa de datos reconciliados tambi√©n puede implementarse de forma virtual en una arquitectura de dos capas, ya que se define como una vista integrada y coherente de los datos de origen. La [figura1.6][figura1.6] muestra de forma gr√°fica este tipo de arquitectura

<figure style="align: center; width:600px;">
    <img src="images/Figura1.6_Almac√©n_de_datos._Arquitectura_de_tres_capas.png">
    <figcaption>Figura 1.6. Almac√©n de datos. Arquitectura de tres capas. (Fuente: UCLM)</figcaption>
</figure>


#### 5.3.2. Arquitecturas orientadas a la empresa

Esta clasificaci√≥n distingue **cinco tipos de arquitecturas** que combinan las capas mencionadas en la primera clasificaci√≥n para dise√±ar almacenes de datos.


***1. Arquitectura de data marts independientes***

Arquitectura preliminar en la que **los distintos data marts son dise√±ados de forma independiente y construidos de forma no integrada**. Suele utilizarse en los inicios de implementaci√≥n de proyectos de almacenes de datos y reemplazada a medida que el proyecto va creciendo.


***2. Arquitectura en bus***

Similar a la anterior, **asegura la integraci√≥n l√≥gica de los data marts creados**, ofreciendo una visi√≥n amplia de los datos de la empresa y permitiendo realizar an√°lisis rigurosos de los procesos que en ella se llevan a cabo.


***3. Arquitectura hub-and-spoke (centro y radio)***

Esta arquitectura es **muy utilizada en almacenes de datos de tama√±os medio y grande**. Su dise√±o pone especial √©nfasis en garantizar la escalabilidad del sistema y permitir a√±adir extensiones al mismo.

Para ello, **los datos se almacenan de forma at√≥mica y normalizada en una capa de datos reconciliados que alimenta a los data marts** construidos que contienen, a su vez, los datos agregados de forma multidimensional. Los usuarios acceden a los data marts, si bien es cierto que tambi√©n pueden hacer consultas directamente sobre los datos reconciliados.


***4. Arquitectura centralizada***

Se trata de un caso particular de la arquitectura hub-and-spoke. En ella, **la capa de datos reconciliados y los data marts se almacenan en un √∫nico repositorio f√≠sico**.


***5. Arquitectura federada***

Se trata de un tipo de arquitectura **muy utilizada en entornos din√°micos, cuando se pretende integrar almacenes de datos o data marts existentes con otros para ofrecer un entorno √∫nico e integrado de soporte a la toma de decisiones**. De esta forma, cada almac√©n de datos y cada data mart es integrado virtual o f√≠sicamente con lo dem√°s. Para ello, se utilizan una serie de t√©cnicas y herramientas avanzadas como son las ontolog√≠as, consultas distribuidas e interoperatividad de metadatos, entre otras.


## 6. Data Lake

### 6.1 Concepto

Un data lake o lago de datos es un repositorio centralizado que permite almacenar, compartir, gobernar y descubrir todos los datos estructurados y no estructurados de una organizaci√≥n a cualquier escala. Es el lugar en el que se vuelcan los datos en bruto.

Los data lakes no requieren un esquema predefinido, se pueden almacenar y procesar datos sin esquema y en cualquier formato sin la necesidad de conocer c√≥mo se van a explotar en el futuro. Esta caracter√≠stica evita que sean necesarios complejos procesos **ETL (Extracci√≥n, Transformaci√≥n y Carga)** (que explicaremos en el pr√≥ximo punto) de limpieza y preparaci√≥n.

Entre las caracter√≠sticas m√°s importantes de los data lakes se encuentra su flexibilidad en almacenar diferentes tipos de datos, que proporciona la agilidad necesaria para los procesos de ingesta. Tambi√©n es muy importante que proporcione suficiente trazabilidad, y de esta manera poder determinar los cambios que han sufrido los datos en los procesos de transformaci√≥n o ingesta.

<figure style="align: center; width:600px;">
    <img src="images/Figura1.7_Data_Lake.webp">
    <figcaption>Figura 1.7. Data Lake. (Fuente: AprenderBigData.com)</figcaption>
</figure>

### 6.2 Data Lake vs Data Warehouse

Los _data lake_ y los _data warehouse_ se utilizan de forma generalizada para el **almacenamiento de big data**, pero, aunque ambos son almacenes de datos, estos **no son t√©rminos intercambiables**. Un data lake o "lago de datos" es un gran conjunto de datos **en bruto**, que todav√≠a **no tiene una finalidad definida**. En cambio, un data warehouse o "almac√©n de datos" es un dep√≥sito de datos que **ya est√°n estructurados y filtrados** y han sido procesados para un **prop√≥sito concreto**.

<figure style="align: center; width:600px;">
    <img src="images/Figura1.8_DataWarehouse_vs_DataLake_1.webp">
    <figcaption>Figura 1.8. Data Warehouse vs Data Lake 1</figcaption>
</figure>

A menudo se confunden estos dos tipos de almacenamiento de datos, pero son mucho m√°s diferentes de lo que puede parecer a simple vista. De hecho, lo √∫nico que tienen en com√∫n es que contienen grandes cantidades de datos. Es importante realizar la distinci√≥n, ya que **los data lake y los data warehouse atienden a diferentes prop√≥sitos**, por lo que requieren un enfoque diferente para ser optimizados adecuadamente.

As√≠, un **data lake almacena datos sin procesar** y que todav√≠a **no tienen una finalidad determinada**. Sus usuarios finales son los **cient√≠ficos de datos** y su _accesibilidad es elevada._ Adem√°s, en un data lake, justamente por esta f√°cil accesibilidad, se pueden actualizar los datos r√°pidamente.

<figure style="align: center; width:600px;">
    <img src="images/Figura1.9_DataWarehouse_vs_DataLake_2.png">
    <figcaption>Figura 1.9. Data Warehouse vs Data Lake 2. (Fuente: Huawei)</figcaption>
</figure>

Por su lado, un **data warehouse cuenta con datos procesados** y que ya se est√°n usando, por lo que tienen una **finalidad concreta**.


[figura1.1]: images/Figura1.1.jpg "Figura 1: Relaci√≥n entre datos, informaci√≥n y conocimiento en el proceso de toma de decisiones"
[figura1.2]: images/Figura1.2_Las_tres_Vs_del_big_data.png "Las tres Vs del big data"
[figura1.3]: images/Figura1.3_Las_ocho_Vs_del_big_data.svg "Las ocho Vs del big data"
[figura1.4]: images/Figura1.4_Grafo.jpg "Grafo que representa las principales autov√≠as de Espa√±a"
[figura1.4]: images/Figura1.4_Almac√©n_de_datos._Arquitectura_de_una_capa.png "Figura 1.5: Almac√©n de datos. Arquitectura de una capa."
[figura1.5]: images/Figura1.5_Almac√©n_de_datos._Arquitectura_de_dos_capas.png "Figura 1.6: Almac√©n de datos. Arquitectura de dos capas."
[figura1.6]: images/Figura1.6_Almac√©n_de_datos._Arquitectura_de_tres_capas.png "Figura 1.6: Almac√©n de datos. Arquitectura de tres capas."
[figura1.7]: images/Figura1.7_Data_Lake.webp "Figura 1.7. Data Lake"
[figura1.8]: images/Figura1.8_DataWarehouse_vs_DataLake_1.webp "Figura 1.10. Data Warehouse vs Data Lake 1"
[figura1.9]: images/Figura1.9_DataWarehouse_vs_DataLake_2.png "Figura 1.9. Data Warehouse vs Data Lake 2"